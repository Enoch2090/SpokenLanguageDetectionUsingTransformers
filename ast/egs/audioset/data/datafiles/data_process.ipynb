{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting pandas\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/12/07/e82b5defa695f09dd0ab1aecda886eb1c1aa6807c34ac3a0d691dc64503c/pandas-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 182 kB/s eta 0:00:01    |██████████████████████▊         | 8.3 MB 187 kB/s eta 0:00:19\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /root/miniconda3/lib/python3.8/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.4.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5701/3135400318.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_path_dict(train,lang):   \n",
    "    if train == True:\n",
    "        log_path = os.path.join(os.getcwd(), \"output\",\"train\",lang)\n",
    "    else:\n",
    "        log_path = os.path.join(os.getcwd(), \"output\",\"valid\",lang)\n",
    "    print(log_path)\n",
    "    for root, dirs, files in os.walk(log_path):\n",
    "        return files\n",
    "\n",
    "def makedir(new_dir):\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.makedirs(new_dir)\n",
    "\n",
    "def split(language_list):\n",
    "    random.seed(1)\n",
    "\n",
    "    MAX_EPOCH = 10\n",
    "    BATCH_SIZE = 2\n",
    "    LR = 0.001\n",
    "    log_interval = 10\n",
    "    val_interval = 1\n",
    "    print(os.getcwd())\n",
    "    dataset_dir = os.path.join(os.getcwd(), \"data\")\n",
    "    print(dataset_dir)\n",
    "    split_dir = os.path.join(os.getcwd(), \"output\")\n",
    "    train_dir = os.path.join(split_dir, \"train\")\n",
    "    valid_dir = os.path.join(split_dir, \"valid\")\n",
    "    test_dir = os.path.join(split_dir, \"test\")\n",
    "\n",
    "    train_pct = 0.7\n",
    "    valid_pct = 0.3\n",
    "    print(dataset_dir)\n",
    "    # for root, dirs, files in os.walk(dataset_dir):\n",
    "    #     # dirs = ['german', 'english', 'french', 'spanish']\n",
    "    for sub_dir in language_list:\n",
    "        print(sub_dir)\n",
    "        imgs = os.listdir(os.path.join(dataset_dir, sub_dir))\n",
    "        imgs = list(filter(lambda x: x.endswith('.wav'), imgs))\n",
    "        random.shuffle(imgs)\n",
    "        img_count = len(imgs)\n",
    "\n",
    "        train_point = int(img_count * train_pct)\n",
    "        valid_point = int(img_count * (train_pct + valid_pct))\n",
    "\n",
    "        for i in range(img_count):\n",
    "            if i < train_point:\n",
    "                out_dir = os.path.join(train_dir, sub_dir)\n",
    "            elif i < valid_point:\n",
    "                out_dir = os.path.join(valid_dir, sub_dir)\n",
    "            else:\n",
    "                out_dir = os.path.join(test_dir, sub_dir)\n",
    "\n",
    "            makedir(out_dir)\n",
    "\n",
    "            target_path = os.path.join(out_dir, imgs[i])\n",
    "            src_path = os.path.join(dataset_dir, sub_dir, imgs[i])\n",
    "\n",
    "            shutil.copy(src_path, target_path)\n",
    "\n",
    "        print('Class:{}, train:{}, valid:{}, test:{}'.format(sub_dir, train_point, valid_point-train_point,\n",
    "                                                                img_count-valid_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/haoyuhuang/Desktop/umsi/2022_win/545/project\n",
      "/Users/haoyuhuang/Desktop/umsi/2022_win/545/project/data\n",
      "/Users/haoyuhuang/Desktop/umsi/2022_win/545/project/data\n",
      "english\n",
      "Class:english, train:98, valid:42, test:0\n",
      "french\n",
      "Class:french, train:77, valid:33, test:0\n"
     ]
    }
   ],
   "source": [
    "language_list = ['english','french']\n",
    "split(language_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/haoyuhuang/Desktop/umsi/2022_win/545/project/output/train/english\n",
      "/Users/haoyuhuang/Desktop/umsi/2022_win/545/project/output/train/french\n"
     ]
    }
   ],
   "source": [
    "train_json_list = []\n",
    "\n",
    "for lang in language_list:\n",
    "    file_list = get_log_path_dict(True,lang)\n",
    "    for i in range(len(file_list)):\n",
    "        train_json_list.append({'wav':\"/root/autodl-tmp/ast/data/sls/audioset/data/audio/train/\"+lang+\"/\" + file_list[i],'labels':lang})\n",
    "dict = {'data':train_json_list}\n",
    "# jsonString = json.dumps(dict, indent=4)\n",
    "with open(\"sample_train_data.json\", \"w\") as outfile:\n",
    "    json.dump(dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/haoyuhuang/Desktop/umsi/2022_win/545/project/output/valid/english\n",
      "/Users/haoyuhuang/Desktop/umsi/2022_win/545/project/output/valid/french\n"
     ]
    }
   ],
   "source": [
    "test_json_list = []\n",
    "for lang in language_list:\n",
    "    file_list = get_log_path_dict(False,lang)\n",
    "    for i in range(len(file_list)):\n",
    "        test_json_list.append({'wav':\"/root/autodl-tmp/ast/data/sls/audioset/data/audio/eval/\"+lang+ \"/\" + file_list[i],'labels':lang})\n",
    "dict = {'data':test_json_list}\n",
    "with open(\"sample_eval_data.json\", \"w\") as outfile:\n",
    "    json.dump(dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.DataFrame({'index':list(range(len(language_list))),'mid':language_list,'display_name':language_list})\n",
    "label_df.to_csv('class_labels_indices.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f901d768b51ab5af11dc080dcb7a8a5ded98c3b1e6a8a32a4c02bf1176767a94"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
